---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am working on applications of deep learning to natural language processing, knowledge graph embeddings and graph neural networks. I received my Ph.D from <a href="https://www.monash.edu/">Monash University</a>, under the supervision of <a href="http://dinhphung.ml">Dinh Phung</a> and <a href="https://scholar.google.com/citations?hl=en&user=4hT6E04AAAAJ&view_op=list_works&sortby=pubdate">Tu Dinh Nguyen</a>. Before that, I obtained my M.Sc in Language Science and Technology from <a href="https://www.uni-saarland.de/en/home.html">Saarland University</a> and my B.Sc from <a href="https://e.uet.vnu.edu.vn">VNU University of Engineering and Technology</a>.

News
======

<div class="torightc" style="height:500px;overflow:auto;">
<ul>
  
<li style="margin-top:0.5em;text-align:justify"> 
  [04/2021] My thesis, entitled <a href="https://bridges.monash.edu/articles/thesis/Representation_Learning_for_Graph-Structured_Data/14450496" target="_blank">"Representation Learning for Graph-Structured Data"</a>, is finally online.
  <br />
  Preprint <a href="https://arxiv.org/abs/2104.07396" target="_blank">Node Co-occurrence based Graph Neural Networks for Knowledge Graph Link Prediction</a>.
  <br />
  Preprint <a href="https://arxiv.org/abs/2104.12128" target="_blank">Automatic Post-Editing for Translating Chinese Novels to Vietnamese</a>.
</li>
  
<li style="margin-top:0.5em;text-align:justify"> 
  [11/2020] The extended abstracts of the preprint papers, <a href="https://arxiv.org/pdf/2008.05089.pdf" target="_blank">Quaternion Graph Neural Networks</a> and <a href="http://arxiv.org/abs/2009.12517" target="_blank">QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings</a>, have been accepted to the NeurIPS 2020 Workshop on Differential Geometry meets Deep Learning (<a href="https://sites.google.com/view/diffgeo4dl/" target="_blank">DiffGeo4DL</a>). 
  <br />
  The codes are available at <a href="https://github.com/daiquocnguyen/QGNN" target="_blank">https://github.com/daiquocnguyen/QGNN</a> and <a href="https://github.com/daiquocnguyen/QuatRE" target="_blank">https://github.com/daiquocnguyen/QuatRE</a>.
</li>
  
<li style="margin-top:0.5em;text-align:justify"> 
  [10/2020] I'm in the top 10% of high-scoring reviewers at NeurIPS 2020.
</li>
  
<li style="margin-top:0.5em;text-align:justify"> 
  [09/2020] <a href="https://daiquocnguyen.github.io/blog/quaternion-graph-neural-networks" target="_blank">A new blog</a> on Quaternion Graph Neural Networks.
  <br />
  Preprint <a href="http://arxiv.org/abs/2009.12517" target="_blank">QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings</a>.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [08/2020] Preprint <a href="https://arxiv.org/pdf/2008.05089.pdf" target="_blank">Quaternion Graph Neural Networks</a>.
  <br />
  Paper <a href="https://arxiv.org/pdf/1911.04822.pdf" target="_blank">A Capsule Network-based Model for Learning Node Embeddings</a> has been accepted to CIKM 2020 (Poster).
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [06/2020] Release the Pytorch implementations of our <a href="https://github.com/daiquocnguyen/R-MeN" target="_blank">ConvKB (NAACL 2018)</a> and <a href="https://github.com/daiquocnguyen/R-MeN" target="_blank">R-MeN (ACL 2020)</a> for knowledge graph completion.
  <br />
  Paper <a href="https://arxiv.org/abs/2006.12100" target="_blank">A Self-Attention Network based Node Embedding Model</a> has been accepted to ECML-PKDD 2020.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [05/2020] Release the Pytorch implementation of our <a href="https://github.com/daiquocnguyen/Graph-Transformer" target="_blank">U2GNN (Graph-Transformer)</a> model for graph classification.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [04/2020] Paper <a href="https://arxiv.org/abs/1907.06080" target="_blank">A Relational Memory-based Embedding Model for Triple Classification and Search Personalization</a> has been accepted to ACL 2020.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [11/2019] Preprint <a href="https://arxiv.org/pdf/1911.04822.pdf" target="_blank">A Capsule Network-based Model for Learning Node Embeddings</a>.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [09/2019] Preprint <a href="https://arxiv.org/pdf/1909.11855.pdf" target="_blank">Universal Self-Attention Network for Graph Classification</a>.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [02/2019] Paper <a href="https://arxiv.org/abs/1808.04122" target="_blank">A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization</a> has been accepted to NAACL 2019.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [04/2018] Paper <a href="http://www.semantic-web-journal.net/system/files/swj1867.pdf" target="_blank">A Convolutional Neural Network-based Model for Knowledge Base Completion and Its Application to Search Personalization</a> has been accepted to Semantic Web Journal.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [02/2018] Papers <a href="https://arxiv.org/abs/1712.02121" target="_blank">A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network</a> and <a href="">VnCoreNLP: A Vietnamese Natural Language Processing Toolkit</a> have been accepted to NAACL 2018.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [12/2017] Paper <a href="">A Fast and Accurate Vietnamese Word Segmenter</a> has been accepted to LREC 2018.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [09/2017] Paper <a href="">Sequence to Sequence Learning for Event Prediction</a> has been accepted to IJCNLP 2017.
</li>

<li style="margin-top:0.5em;text-align:justify"> 
  [06/2017] Paper <a href="">A Mixture Model for Learning Multi-Sense Word Embeddings</a> has been accepted to *SEM 2017.
</li>

</ul>
</div>


<p></p>

Academic service
======

<ul>

<li style="margin-top:0.5em;text-align:justify"> 
  Program Committee: NeurIPS (2020-top 10% of high-scoring reviewers, 2021), ICLR (2021), IJCAI (2021), ICML (2021), ECML-PKDD (2021), NAACL (2021), EMNLP (2021).
</li>

</ul>
